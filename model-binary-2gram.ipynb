{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom sklearn.preprocessing import StandardScaler\n\nfrom transformers import BertTokenizer\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import GlobalAveragePooling1D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import MaxPooling1D\nfrom tensorflow.keras.layers import GlobalAveragePooling1D\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# plots and images\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\n\n#sklearn processing\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#configs\nmax_tokens = 20000","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-26T19:53:16.736731Z","iopub.execute_input":"2022-11-26T19:53:16.737157Z","iopub.status.idle":"2022-11-26T19:53:16.748178Z","shell.execute_reply.started":"2022-11-26T19:53:16.737116Z","shell.execute_reply":"2022-11-26T19:53:16.747025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_raw = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/sample_submission.csv')\ntrain_data_raw = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/train.csv')\ntest_from_comp = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-26T19:54:26.846377Z","iopub.execute_input":"2022-11-26T19:54:26.847457Z","iopub.status.idle":"2022-11-26T19:54:26.928592Z","shell.execute_reply.started":"2022-11-26T19:54:26.847420Z","shell.execute_reply":"2022-11-26T19:54:26.927666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(train_data_raw, test_size=0.2, random_state=21) #20% for test\ntrain, val = train_test_split(train, test_size=0.1, random_state=21) # 10% for validation\ntrain\n\ntargets=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n\nsc_y = StandardScaler()\ntrain_targets = sc_y.fit_transform(train[targets])\nval_targets = sc_y.transform(val[targets])\ntest_targets = sc_y.transform(test[targets])\n\ntrain_targets_ds = tf.convert_to_tensor(train_targets)\nval_targets_ds = tf.convert_to_tensor(val_targets)\ntest_targets_ds = tf.convert_to_tensor(test_targets)\n\ntrain_text_only = tf.convert_to_tensor(train['full_text'])\nval_text_only = tf.convert_to_tensor(val['full_text'])\ntest_text_only = tf.convert_to_tensor(test['full_text'])\n\n\n## for submission \nall_sc_y = StandardScaler()\nall_train_targets = all_sc_y.fit_transform(train_data_raw[targets])\nall_train_targets_ds = tf.convert_to_tensor(all_train_targets)\nall_train_text_only = tf.convert_to_tensor(train_data_raw['full_text'])\n\nall_test_text_only = tf.convert_to_tensor(test_from_comp['full_text'])\n","metadata":{"execution":{"iopub.status.busy":"2022-11-26T19:54:27.747902Z","iopub.execute_input":"2022-11-26T19:54:27.748589Z","iopub.status.idle":"2022-11-26T19:54:27.783289Z","shell.execute_reply.started":"2022-11-26T19:54:27.748551Z","shell.execute_reply":"2022-11-26T19:54:27.782364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text_vectorization = layers.TextVectorization(\n#     max_tokens=max_tokens,\n#     output_mode=\"multi_hot\"\n# )\n\ntext_vectorization = layers.TextVectorization(\n    ngrams=2,\n    max_tokens=max_tokens,\n    output_mode=\"multi_hot\",\n)\n\n#use the dataset to index the dataset vocab via the adapt method\ntext_vectorization.adapt(train_text_only)\n\ntrain_features_ds = text_vectorization(train_text_only)\nval_features_ds = text_vectorization(val_text_only)\ntest_features_ds = text_vectorization(test_text_only)\n\n#for submission\nall_train_features_ds = text_vectorization(all_train_text_only)\nall_test_features_ds = text_vectorization(all_test_text_only)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-26T20:00:08.440205Z","iopub.execute_input":"2022-11-26T20:00:08.440675Z","iopub.status.idle":"2022-11-26T20:00:13.098924Z","shell.execute_reply.started":"2022-11-26T20:00:08.440634Z","shell.execute_reply":"2022-11-26T20:00:13.097764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(max_tokens=max_tokens, hidden_dim=32):\n    inputs = keras.Input(shape=(max_tokens,))\n\n    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n    x = layers.Dropout(rate=0.5)(x)\n    \n    x = layers.Dense(hidden_dim, activation=\"relu\")(x)\n    x = layers.Dropout(rate=0.5)(x)\n    \n    x = layers.Dense(hidden_dim, activation=\"relu\")(x)\n    x = layers.Dropout(rate=0.5)(x)\n\n\n    outputs = layers.Dense(6, activation=None)(x)\n    \n    model = keras.Model(inputs, outputs)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(),\n        loss=\"mean_absolute_error\",\n        metrics=[tf.keras.metrics.RootMeanSquaredError(\n                name='root_mean_squared_error', dtype=None\n            )]\n    )\n    return model\n\n#train model and test\nmodel = get_model()\nmodel.summary()\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\", save_best_only=True)\n]\nhist = model.fit(\n    x=train_features_ds,\n    y=train_targets_ds,\n    validation_data = (\n        val_features_ds, val_targets_ds\n    ),\n    epochs=100,\n    callbacks=callbacks\n)\n\nmodel = keras.models.load_model(\"binary_2gram.keras\")\nprint(f\"Test acc: {model.evaluate(test_features_ds, test_targets_ds, 1)}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-11-26T20:03:00.928095Z","iopub.execute_input":"2022-11-26T20:03:00.928771Z","iopub.status.idle":"2022-11-26T20:03:39.452702Z","shell.execute_reply.started":"2022-11-26T20:03:00.928727Z","shell.execute_reply":"2022-11-26T20:03:39.451616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grab history\nhistory = hist.history\n\nfig = plt.figure(figsize=(16, 4))\nax = fig.add_subplot(1, 3, 1)\n\nplt.plot(history['loss'], lw=2, color='darkgoldenrod')\nplt.plot(history['val_loss'], lw=2, color='indianred')\nplt.legend(['Train', 'Validation'], fontsize=10)\n#plt.ylim(0.5,0.7)\nax.set_xlabel('Epochs', size=10)\nax.set_title('Loss');\n\nax = fig.add_subplot(1, 3, 2)\n\nplt.plot(history['root_mean_squared_error'], lw=2, color='darkgoldenrod')\nplt.plot(history['val_root_mean_squared_error'], lw=2, color='indianred')\nplt.legend(['Train', 'Validation'], fontsize=10)\n#plt.ylim(0.5,0.7)\nax.set_xlabel('Epochs', size=10)\nax.set_title('RMSE');\n","metadata":{"execution":{"iopub.status.busy":"2022-11-26T20:03:56.731032Z","iopub.execute_input":"2022-11-26T20:03:56.731698Z","iopub.status.idle":"2022-11-26T20:03:57.096287Z","shell.execute_reply.started":"2022-11-26T20:03:56.731663Z","shell.execute_reply":"2022-11-26T20:03:57.095324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\nmodel = get_model()\nmodel.summary()\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\", save_best_only=True)\n]\nhist = model.fit(\n    x=all_train_features_ds,\n    y=all_train_targets_ds,\n    validation_data = None,\n    epochs=25,\n    callbacks=callbacks\n)\n\nmodel = keras.models.load_model(\"binary_1gram.keras\")","metadata":{"execution":{"iopub.status.busy":"2022-11-26T20:04:26.878966Z","iopub.execute_input":"2022-11-26T20:04:26.879334Z","iopub.status.idle":"2022-11-26T20:04:38.047422Z","shell.execute_reply.started":"2022-11-26T20:04:26.879302Z","shell.execute_reply":"2022-11-26T20:04:38.046451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission to contest","metadata":{}},{"cell_type":"code","source":"test_predictions = model.predict(all_test_features_ds)\ntest_predictions = pd.DataFrame(all_sc_y.inverse_transform(test_predictions))\n\ntest_from_comp['cohesion'] = test_predictions[0]\ntest_from_comp['syntax'] = test_predictions[1]\ntest_from_comp['vocabulary'] = test_predictions[2]\ntest_from_comp['phraseology'] = test_predictions[3]\ntest_from_comp['grammar'] = test_predictions[4]\ntest_from_comp['conventions'] = test_predictions[5]\ntest_from_comp","metadata":{"execution":{"iopub.status.busy":"2022-11-26T20:04:44.701351Z","iopub.execute_input":"2022-11-26T20:04:44.701888Z","iopub.status.idle":"2022-11-26T20:04:44.755451Z","shell.execute_reply.started":"2022-11-26T20:04:44.701848Z","shell.execute_reply":"2022-11-26T20:04:44.754402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = test_from_comp.drop(\"full_text\",axis=1)\nres.to_csv(\"/kaggle/working/submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T20:04:48.839521Z","iopub.execute_input":"2022-11-26T20:04:48.839895Z","iopub.status.idle":"2022-11-26T20:04:48.847708Z","shell.execute_reply.started":"2022-11-26T20:04:48.839863Z","shell.execute_reply":"2022-11-26T20:04:48.846436Z"},"trusted":true},"execution_count":null,"outputs":[]}]}