{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/joeroberts/inference-bert-transfer-learning?scriptVersionId=112948823\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# used this tutorial to help. \n# https://www.tensorflow.org/tfmodels/nlp/fine_tune_bert\n# https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n# https://www.tensorflow.org/tfmodels/nlp/fine_tune_bert#import_libraries\n\nimport numpy as np\nimport pandas as pd \nfrom sklearn.preprocessing import StandardScaler\n\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import GlobalAveragePooling1D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import MaxPooling1D\nfrom tensorflow.keras.layers import GlobalAveragePooling1D\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom transformers import BertTokenizer, AutoTokenizer, AutoModelForSequenceClassification, TFBertModel, BertConfig\n\nfrom tqdm import tqdm\n# plots and images\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\n\n#sklearn processing\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n\nimport os\n\n# import wandb\n\n\n# #configs\n# max_tokens = 20000\n# embed_dim  = 300\n# num_heads  = 2\n# dense_dim  = 32\n\n\ndeveloping = True\n\nBATCH_SIZE = 12\nBUFFER_SIZE = 3200\nSEQ_LEN = 1536\nAUTO = tf.data.AUTOTUNE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-04T22:17:43.774736Z","iopub.execute_input":"2022-12-04T22:17:43.775418Z","iopub.status.idle":"2022-12-04T22:17:43.793511Z","shell.execute_reply.started":"2022-12-04T22:17:43.775382Z","shell.execute_reply":"2022-12-04T22:17:43.79228Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/feedback-prize-english-language-learning/sample_submission.csv\n/kaggle/input/feedback-prize-english-language-learning/train.csv\n/kaggle/input/feedback-prize-english-language-learning/test.csv\n/kaggle/input/bertbasecased/config.json\n/kaggle/input/bertbasecased/tokenizer.json\n/kaggle/input/bertbasecased/tokenizer_config.json\n/kaggle/input/bertbasecased/pytorch_model.bin\n/kaggle/input/bertbasecased/vocab.txt\n/kaggle/input/inference/bert_transfer_model.keras\n/kaggle/input/glove/glove.6B.300d.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_submission_raw = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/sample_submission.csv')\ntrain_data_raw = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/train.csv')\ntest_from_comp = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n\n\ntrain, test = train_test_split(train_data_raw, test_size=0.2, random_state=21) #20% for test\ntrain, val = train_test_split(train, test_size=0.1, random_state=21) # 10% for validation\n\n\ntargets=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n\ntrain_y = train[targets]\nval_y = val[targets]\ntest_y = test[targets]\n\ntrain_x = train['full_text']\nval_x = val['full_text']\ntest_x = test['full_text']\ntest_data_comp = test_from_comp['full_text']\n","metadata":{"execution":{"iopub.status.busy":"2022-12-04T22:17:46.743868Z","iopub.execute_input":"2022-12-04T22:17:46.744241Z","iopub.status.idle":"2022-12-04T22:17:46.963395Z","shell.execute_reply.started":"2022-12-04T22:17:46.744209Z","shell.execute_reply":"2022-12-04T22:17:46.962447Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"/kaggle/input/bertbasecased/\")\n\ndef get_ids_mask(inputs):\n    input_ids_part_one = []\n    attention_mask_part_one = []\n    \n    input_ids_part_two = []\n    attention_mask_part_two = []\n    \n    input_ids_part_three = []\n    attention_mask_part_three = []\n    \n\n    for x in tqdm(inputs):\n        tokens = tokenizer(x, padding=\"max_length\", truncation=True, max_length=SEQ_LEN, return_tensors=\"np\")\n        ids = tokens[\"input_ids\"]\n        mask = tokens[\"attention_mask\"]\n        \n        input_ids_part_one.append(ids[0][:512])\n        attention_mask_part_one.append(mask[0][:512])\n        \n        input_ids_part_two.append(ids[0][512:1024])\n        attention_mask_part_two.append(mask[0][512:1024])\n        \n        input_ids_part_three.append(ids[0][1024:1536])\n        attention_mask_part_three.append(mask[0][1024:1536])\n        \n    input_ids_part_one = np.array(input_ids_part_one).squeeze()\n    attention_mask_part_one = np.array(attention_mask_part_one).squeeze()\n    \n    input_ids_part_two = np.array(input_ids_part_two).squeeze()\n    attention_mask_part_two = np.array(attention_mask_part_two).squeeze()\n    \n    input_ids_part_three = np.array(input_ids_part_three).squeeze()\n    attention_mask_part_three = np.array(attention_mask_part_three).squeeze()\n    \n    return input_ids_part_one, attention_mask_part_one, input_ids_part_two, attention_mask_part_two, input_ids_part_three, attention_mask_part_three\n\n\ntrain_input_ids_part_one, train_attention_mask_part_one, train_input_ids_part_two, train_attention_mask_part_two, train_input_ids_part_three, train_attention_mask_part_three = get_ids_mask(train_x)\nval_input_ids_part_one, val_attention_mask_part_one, val_input_ids_part_two, val_attention_mask_part_two, val_input_ids_part_three, val_attention_mask_part_three = get_ids_mask(val_x)\ntest_input_ids_part_one, test_attention_mask_part_one, test_input_ids_part_two, test_attention_mask_part_two, test_input_ids_part_three, test_attention_mask_part_three = get_ids_mask(test_x)\ntest_data_comp_input_ids_part_one, test_data_comp_attention_mask_part_one, test_data_comp_input_ids_part_two, test_data_comp_attention_mask_part_two, test_data_comp_input_ids_part_three, test_data_comp_attention_mask_part_three = get_ids_mask(test_data_comp)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-04T22:17:55.048224Z","iopub.execute_input":"2022-12-04T22:17:55.04857Z","iopub.status.idle":"2022-12-04T22:18:33.018128Z","shell.execute_reply.started":"2022-12-04T22:17:55.04854Z","shell.execute_reply":"2022-12-04T22:18:33.017153Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"100%|██████████| 2815/2815 [00:27<00:00, 102.06it/s]\n100%|██████████| 313/313 [00:03<00:00, 101.12it/s]\n100%|██████████| 783/783 [00:07<00:00, 109.84it/s]\n100%|██████████| 3/3 [00:00<00:00, 88.40it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"class MeanPool(keras.layers.Layer):\n    def call(self, x, mask=None):\n        broad_mask = tf.cast(tf.expand_dims(mask, -1), \"float32\")\n        x = tf.math.reduce_sum( x * broad_mask, axis=1)\n        x = x / tf.math.maximum(tf.reduce_sum(broad_mask, axis=1), tf.constant([1e-9]))\n        return x \n","metadata":{"execution":{"iopub.status.busy":"2022-12-04T22:19:59.898742Z","iopub.execute_input":"2022-12-04T22:19:59.899089Z","iopub.status.idle":"2022-12-04T22:19:59.905744Z","shell.execute_reply.started":"2022-12-04T22:19:59.899061Z","shell.execute_reply":"2022-12-04T22:19:59.90477Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model(\n    \"/kaggle/input/inference/bert_transfer_model.keras\",                 \n   custom_objects={\n        \"MeanPool\": MeanPool\n\n        })","metadata":{"execution":{"iopub.status.busy":"2022-12-04T22:21:05.577894Z","iopub.execute_input":"2022-12-04T22:21:05.578272Z","iopub.status.idle":"2022-12-04T22:21:20.699589Z","shell.execute_reply.started":"2022-12-04T22:21:05.578241Z","shell.execute_reply":"2022-12-04T22:21:20.698503Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.evaluate(\n    {\n            'tokens_one': test_input_ids_part_one,\n            'attention_mask_one': test_attention_mask_part_one,\n            \n            'tokens_two': test_input_ids_part_two,\n            'attention_mask_two': test_attention_mask_part_two,\n            \n            'tokens_three': test_input_ids_part_three,\n            'attention_mask_three': test_attention_mask_part_three,\n        },\n    test_y , 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T22:21:25.969233Z","iopub.execute_input":"2022-12-04T22:21:25.969863Z","iopub.status.idle":"2022-12-04T22:22:52.715502Z","shell.execute_reply.started":"2022-12-04T22:21:25.969829Z","shell.execute_reply":"2022-12-04T22:22:52.714465Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"2022-12-04 22:21:26.069589: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"783/783 [==============================] - 69s 81ms/step - loss: 0.2577 - root_mean_squared_error: 0.5077\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[0.2577137351036072, 0.5076553225517273]"},"metadata":{}}]},{"cell_type":"code","source":"test_predictions = model.predict(x={\n            'tokens_one': test_data_comp_input_ids_part_one,\n            'attention_mask_one': test_data_comp_attention_mask_part_one,\n            \n            'tokens_two': test_data_comp_input_ids_part_two,\n            'attention_mask_two': test_data_comp_attention_mask_part_two,\n            \n            'tokens_three': test_data_comp_input_ids_part_three,\n            'attention_mask_three': test_data_comp_attention_mask_part_three,\n        })\n\n\ntest_predictions = pd.DataFrame(test_predictions)\ntest_from_comp['cohesion'] = test_predictions[0]\ntest_from_comp['syntax'] = test_predictions[1]\ntest_from_comp['vocabulary'] = test_predictions[2]\ntest_from_comp['phraseology'] = test_predictions[3]\ntest_from_comp['grammar'] = test_predictions[4]\ntest_from_comp['conventions'] = test_predictions[5]\ntest_from_comp","metadata":{"execution":{"iopub.status.busy":"2022-12-04T22:22:52.717604Z","iopub.execute_input":"2022-12-04T22:22:52.71799Z","iopub.status.idle":"2022-12-04T22:23:00.777964Z","shell.execute_reply.started":"2022-12-04T22:22:52.717949Z","shell.execute_reply":"2022-12-04T22:23:00.777032Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text  cohesion  \\\n0  0000C359D63E  when a person has no experience on a job their...  2.930954   \n1  000BAD50D026  Do you think students would benefit from being...  2.895386   \n2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...  3.526787   \n\n     syntax  vocabulary  phraseology   grammar  conventions  \n0  2.974277    3.140543     3.016876  2.738055     2.684046  \n1  2.713362    2.950342     2.719229  2.628312     2.732231  \n2  3.520761    3.643239     3.608127  3.561570     3.626666  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>when a person has no experience on a job their...</td>\n      <td>2.930954</td>\n      <td>2.974277</td>\n      <td>3.140543</td>\n      <td>3.016876</td>\n      <td>2.738055</td>\n      <td>2.684046</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>Do you think students would benefit from being...</td>\n      <td>2.895386</td>\n      <td>2.713362</td>\n      <td>2.950342</td>\n      <td>2.719229</td>\n      <td>2.628312</td>\n      <td>2.732231</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>Thomas Jefferson once states that \"it is wonde...</td>\n      <td>3.526787</td>\n      <td>3.520761</td>\n      <td>3.643239</td>\n      <td>3.608127</td>\n      <td>3.561570</td>\n      <td>3.626666</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"res = test_from_comp.drop(\"full_text\",axis=1)\nres.to_csv(\"/kaggle/working/submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T22:23:15.765744Z","iopub.execute_input":"2022-12-04T22:23:15.766129Z","iopub.status.idle":"2022-12-04T22:23:15.776862Z","shell.execute_reply.started":"2022-12-04T22:23:15.766083Z","shell.execute_reply":"2022-12-04T22:23:15.775882Z"},"trusted":true},"execution_count":13,"outputs":[]}]}